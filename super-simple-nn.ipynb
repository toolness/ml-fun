{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.testing import assert_almost_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at iteration 0: 0.6960558242178866\n",
      "cost at iteration 100: 0.6929867887355738\n",
      "cost at iteration 200: 0.6922462617773397\n",
      "cost at iteration 300: 0.6865890109283816\n",
      "cost at iteration 400: 0.6374850000789614\n",
      "cost at iteration 500: 0.5063366329094551\n",
      "cost at iteration 600: 0.24494224360510392\n",
      "cost at iteration 700: 0.0915469133772983\n",
      "cost at iteration 800: 0.05089111333463649\n",
      "cost at iteration 900: 0.034477698445246695\n",
      "cost at iteration 1000: 0.025856753007441634\n",
      "cost at iteration 1100: 0.020601465948381907\n",
      "cost at iteration 1200: 0.017082139409163984\n",
      "cost at iteration 1300: 0.014568584508727361\n",
      "cost at iteration 1400: 0.012687400482552087\n",
      "cost at iteration 1500: 0.011228647852513835\n",
      "cost at iteration 1600: 0.010065565651741971\n",
      "cost at iteration 1700: 0.009117240056884511\n",
      "cost at iteration 1800: 0.008329668454476488\n",
      "cost at iteration 1900: 0.007665468228175891\n",
      "cost at iteration 2000: 0.007097960769063973\n",
      "cost at iteration 2100: 0.00660760840370299\n",
      "cost at iteration 2200: 0.006179782389089394\n",
      "cost at iteration 2300: 0.005803316910980904\n",
      "cost at iteration 2400: 0.00546954463742291\n",
      "cost at iteration 2500: 0.005171636891437952\n",
      "cost at iteration 2600: 0.004904141996561449\n",
      "cost at iteration 2700: 0.0046626557805682384\n",
      "cost at iteration 2800: 0.004443582179887452\n",
      "cost at iteration 2900: 0.0042439564984879975\n",
      "cost at iteration 3000: 0.0040613130194073225\n",
      "cost at iteration 3100: 0.0038935845245969417\n",
      "cost at iteration 3200: 0.0037390251105135497\n",
      "cost at iteration 3300: 0.003596150241846593\n",
      "cost at iteration 3400: 0.0034636897193797327\n",
      "cost at iteration 3500: 0.003340550433252222\n",
      "cost at iteration 3600: 0.003225786609225934\n",
      "cost at iteration 3700: 0.0031185758487546865\n",
      "cost at iteration 3800: 0.0030181996897365067\n",
      "cost at iteration 3900: 0.002924027724472616\n",
      "cost at iteration 4000: 0.002835504538852294\n",
      "cost at iteration 4100: 0.0027521389056332163\n",
      "cost at iteration 4200: 0.0026734947912097923\n",
      "cost at iteration 4300: 0.0025991838309167093\n",
      "cost at iteration 4400: 0.0025288590008482473\n",
      "cost at iteration 4500: 0.0024622092702146657\n",
      "cost at iteration 4600: 0.0023989550616518632\n",
      "cost at iteration 4700: 0.0023388443807303714\n",
      "cost at iteration 4800: 0.002281649502465213\n",
      "cost at iteration 4900: 0.002227164123604663\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.power(np.e, -x))\n",
    "\n",
    "assert sigmoid(0) == 0.5\n",
    "assert_almost_equal(sigmoid(-100), 0)\n",
    "assert_almost_equal(sigmoid(100), 1)\n",
    "\n",
    "def sigmoid_gradient(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "assert_almost_equal(sigmoid_gradient(-100), 0)\n",
    "assert_almost_equal(sigmoid_gradient(100), 0)\n",
    "\n",
    "def forward_prop_nn(w1, b1, w2, b2, x):\n",
    "    z1 = np.dot(w1, x) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(w2, a1) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    return a2\n",
    "\n",
    "xnor_w_1 = np.array([\n",
    "    [-20, -20],          # Weights for \"(NOT x[0]) AND (NOT x[1])\" \n",
    "    [ 20,  20],          # Weights for \"x[0] AND x[1]\"\n",
    "]) * 10\n",
    "xnor_b_1 = np.array([\n",
    "    [ 10],               # Bias for \"(NOT x[0]) AND (NOT x[1])\"\n",
    "    [-30],               # Bias for \"x[0] AND x[1]\"\n",
    "]) * 10\n",
    "xnor_w_2 = np.array([\n",
    "    [ 20,  20],          # Weights for \"x[0] OR x[1]\"\n",
    "]) * 10\n",
    "xnor_b_2 = np.array([\n",
    "    [-10],               # Bias for \"x[0] OR x[1]\"\n",
    "]) * 10\n",
    "\n",
    "def xnor_nn(x0, x1):\n",
    "    return forward_prop_nn(xnor_w_1, xnor_b_1, xnor_w_2, xnor_b_2, np.array(x).reshape(2, 1))[0][0]\n",
    "\n",
    "xnor_truth_table = {\n",
    "    (1, 1): 1.0,\n",
    "    (0, 0): 1.0,\n",
    "    (0, 1): 0.0,\n",
    "    (1, 0): 0.0,\n",
    "}\n",
    "\n",
    "for x, y in xnor_truth_table.items():\n",
    "    assert_almost_equal(xnor_nn(x[0], x[1]), y)\n",
    "\n",
    "def train_nn(examples, iterations, learning_rate):\n",
    "    m = len(examples)\n",
    "    np.random.seed(1)\n",
    "    w1 = np.random.rand(2, 2)\n",
    "    b1 = np.zeros([2, 1])\n",
    "    w2 = np.random.rand(1, 2)\n",
    "    b2 = np.zeros([1, 1])\n",
    "    for i in range(iterations):\n",
    "        dw1 = np.zeros([2, 2])\n",
    "        db1 = np.zeros([2, 1])\n",
    "        dw2 = np.zeros([1, 2])\n",
    "        db2 = np.zeros([1, 1])\n",
    "        cost = np.zeros([1, 1])\n",
    "        for x, y in examples:\n",
    "            z1 = np.dot(w1, x) + b1\n",
    "            a1 = sigmoid(z1)\n",
    "            z2 = np.dot(w2, a1) + b2\n",
    "            a2 = sigmoid(z2)\n",
    "\n",
    "            cost += -y * np.log(a2) - (1 - y) * np.log(1 - a2)\n",
    "\n",
    "            dz2 = a2 - y\n",
    "            dw2 += np.dot(dz2, a1.T)\n",
    "            db2 += dz2\n",
    "            dz1 = np.dot(w2.T, dz2) * sigmoid_gradient(z1)\n",
    "            dw1 += np.dot(dz1, x.T)\n",
    "            db1 += dz1\n",
    "        dw1 /= m\n",
    "        db1 /= m\n",
    "        dw2 /= m\n",
    "        db2 /= m\n",
    "        cost /= m\n",
    "        w1 -= learning_rate * dw1\n",
    "        b1 -= learning_rate * db1\n",
    "        w2 -= learning_rate * dw2\n",
    "        b2 -= learning_rate * db2\n",
    "        if i % 100 == 0:\n",
    "            print(f\"cost at iteration {i}: {cost[0][0]}\")\n",
    "    return (w1, b1, w2, b2)\n",
    "\n",
    "xnor_examples = [(np.array(x).reshape(2, 1), np.array([[y]])) for x, y in xnor_truth_table.items()]\n",
    "w1, b1, w2, b2 = train_nn(xnor_examples, 5000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in xnor_truth_table.items():\n",
    "    y_hat = forward_prop_nn(w1, b1, w2, b2, np.array(x).reshape(2, 1))[0][0]\n",
    "    assert_almost_equal(y_hat, y, decimal=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
